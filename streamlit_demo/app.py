# --------------------------------------------------------
# InternVL
# Copyright (c) 2024 OpenGVLab
# Licensed under The MIT License [see LICENSE for details]
# --------------------------------------------------------

import argparse
import base64
import datetime
import hashlib
import json
import os
import random
import re
import sys
import subprocess
import urllib.parse
# from streamlit_js_eval import streamlit_js_eval
from functools import partial
from io import BytesIO
import tempfile

import cv2
import numpy as np
import requests
import streamlit as st
from constants import LOGDIR, server_error_msg
from library import Library
from PIL import Image, ImageDraw, ImageFont
# from streamlit_image_select import image_select  # å·²ç§»é™¤ç¤ºä¾‹å›¾ç‰‡åŠŸèƒ½
import imageio_ffmpeg

custom_args = sys.argv[1:]
parser = argparse.ArgumentParser()
parser.add_argument('--controller_url', type=str, default='http://localhost:40000', help='url of the controller')
parser.add_argument('--sd_worker_url', type=str, default='http://0.0.0.0:40006', help='url of the stable diffusion worker')
parser.add_argument('--chatgpt_worker_url', type=str, default='http://localhost:40002', help='url of the chatgpt worker')
parser.add_argument('--max_image_limit', type=int, default=10000, help='maximum number of images')
parser.add_argument('--use_chatgpt', action='store_true', help='use ChatGPT instead of local model')
args = parser.parse_args(custom_args)
controller_url = args.controller_url
sd_worker_url = args.sd_worker_url
chatgpt_worker_url = args.chatgpt_worker_url
max_image_limit = args.max_image_limit
use_chatgpt = args.use_chatgpt
print('args:', args)


def get_conv_log_filename():
    t = datetime.datetime.now()
    name = os.path.join(LOGDIR, f'{t.year}-{t.month:02d}-{t.day:02d}-conv.json')
    return name


def get_model_list():
    if use_chatgpt:
        return ['gpt-4o-mini', 'gpt-4o', 'gpt-3.5-turbo']
    
    ret = requests.post(controller_url + '/refresh_all_workers')
    assert ret.status_code == 200
    ret = requests.post(controller_url + '/list_models')
    models = ret.json()['models']
    models = [item for item in models if 'InternVL2-Det' not in item and 'InternVL2-Gen' not in item]
    return models


def is_video_url(url):
    """æ£€æŸ¥æ˜¯å¦ä¸ºè§†é¢‘é“¾æ¥"""
    video_patterns = [
        r'(?:https?://)?(?:www\.)?youtube\.com/watch\?v=',
        r'(?:https?://)?(?:www\.)?youtube\.com/shorts/',
        r'(?:https?://)?youtu\.be/',
        r'(?:https?://)?(?:www\.)?vimeo\.com/',
        r'(?:https?://)?(?:www\.)?bilibili\.com/',
        r'(?:https?://)?(?:www\.)?dailymotion\.com/',
        r'(?:https?://)?(?:www\.)?twitch\.tv/',
        r'\.mp4(?:\?.*)?$',
        r'\.mov(?:\?.*)?$',
        r'\.avi(?:\?.*)?$',
        r'\.mkv(?:\?.*)?$',
        r'\.webm(?:\?.*)?$',
    ]
    return any(re.search(pattern, url) for pattern in video_patterns)


def get_video_info(url):
    """è·å–è§†é¢‘ä¿¡æ¯è€Œä¸ä¸‹è½½"""
    try:
        cmd = [
            # 'C:\\Users\\PDLP-013-Eric\\Anaconda3\\envs\\video\\python.exe', '-m', 'yt_dlp',
            'python', '-m', 'yt_dlp',
            '--dump-json',
            '--no-playlist',
            url
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        
        if result.returncode != 0:
            raise Exception(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {result.stderr}")
        
        info = json.loads(result.stdout)
        return info
        
    except subprocess.TimeoutExpired:
        raise Exception("è·å–è§†é¢‘ä¿¡æ¯è¶…æ—¶")
    except Exception as e:
        raise Exception(f"è·å–è§†é¢‘ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")


def parse_youtube_subtitle_json(json_content):
    """è§£æYouTubeå­—å¹•JSONæ ¼å¼ï¼Œè½¬æ¢ä¸ºå¯è¯»æ–‡æœ¬"""
    try:
        import json
        data = json.loads(json_content)
        
        # æå–æ‰€æœ‰æ–‡æœ¬ç‰‡æ®µ
        text_segments = []
        for event in data.get('events', []):
            if 'segs' in event:
                for seg in event['segs']:
                    if 'utf8' in seg:
                        text_segments.append({
                            'text': seg['utf8'],
                            'start_ms': event.get('tStartMs', 0),
                            'duration_ms': event.get('dDurationMs', 0)
                        })
        
        # æŒ‰æ—¶é—´æ’åºå¹¶åˆå¹¶
        text_segments.sort(key=lambda x: x['start_ms'])
        
        # è½¬æ¢ä¸ºæ—¶é—´æˆ³æ ¼å¼
        result = []
        current_text = ""
        current_start = 0
        
        for seg in text_segments:
            if seg['text'] == '\n':
                if current_text.strip():
                    # è½¬æ¢æ¯«ç§’ä¸ºæ—¶é—´æ ¼å¼
                    start_time = f"{current_start//1000//60:02d}:{(current_start//1000)%60:02d}.{current_start%1000//10:02d}"
                    result.append(f"{start_time} --> {current_text.strip()}")
                current_text = ""
                current_start = 0
            else:
                if not current_text:
                    current_start = seg['start_ms']
                current_text += seg['text']
        
        # å¤„ç†æœ€åä¸€æ®µ
        if current_text.strip():
            start_time = f"{current_start//1000//60:02d}:{(current_start//1000)%60:02d}.{current_start%1000//10:02d}"
            result.append(f"{start_time} --> {current_text.strip()}")
        
        return '\n'.join(result)
    except Exception as e:
        return json_content  # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å†…å®¹


def extract_video_subtitles(url):
    """æå–è‹±æ–‡å­—å¹•æ–‡æœ¬ï¼ˆä¼˜å…ˆäººå·¥å­—å¹•ï¼Œå…¶æ¬¡è‡ªåŠ¨å­—å¹•ï¼‰ï¼Œè¿”å›åŒ…å« content çš„ç»“æ„ã€‚"""
    try:
        info = get_video_info(url)
        # ä¼˜å…ˆé¡ºåºï¼šsubtitles(äººå·¥) > automatic_captions(è‡ªåŠ¨)
        tracks_order = [('subtitles', 'subtitle'), ('automatic_captions', 'auto')]
        # è‹±æ–‡è¯­è¨€ä¼˜å…ˆåˆ—è¡¨ï¼Œå…¶æ¬¡ä¸­æ–‡
        lang_priority = ['en', 'en-US', 'en-GB', 'en-us', 'en-gb', 'zh', 'zh-CN', 'zh-cn', 'zh-TW', 'zh-tw']
        import requests as _req

        for kind_key, kind_name in tracks_order:
            tracks = info.get(kind_key, {}) or {}
            if not tracks:
                continue
            # æ„é€ å€™é€‰è¯­è¨€ï¼šæŒ‰ä¼˜å…ˆè¡¨æ’åºï¼Œå…¶æ¬¡å…¶å®ƒ
            langs_sorted = []
            seen = set()
            for lp in lang_priority:
                if lp in tracks and lp not in seen:
                    langs_sorted.append(lp)
                    seen.add(lp)
            for l in tracks.keys():
                if l not in seen:
                    langs_sorted.append(l)

            for lang in langs_sorted:
                entries = tracks.get(lang, []) or []
                # é€‰æ‹©å¯ç”¨çš„æ¡ç›®ï¼ˆé€šå¸¸åŒ…å«å¤šè´¨é‡ï¼Œå–ç¬¬ä¸€ä¸ªå¯è®¿é—®çš„ï¼‰
                for ent in entries:
                    url_ = ent.get('url')
                    if not url_:
                        continue
                    try:
                        r = _req.get(url_, timeout=30)
                        if r.status_code == 200 and r.text.strip():
                            return [{
                                'lang': lang,
                                'kind': kind_name,
                                'content': r.text,
                                'source_url': url_,
                            }]
                    except Exception:
                        continue
        return None
    except Exception:
        return None


def stream_video_frames(url):
    """æµå¼å¤„ç†è§†é¢‘å¸§ï¼Œä¸ä¸‹è½½æ•´ä¸ªæ–‡ä»¶"""
    try:
        # è·å–è§†é¢‘ä¿¡æ¯
        with st.spinner('Getting video information...'):
            video_info = get_video_info(url)
        
        duration = video_info.get('duration', 0)
        title = video_info.get('title', 'Unknown')
        
        # å°è¯•æå–å­—å¹•
        subtitles = None
        with st.spinner('Extracting subtitles...'):
            subtitles = extract_video_subtitles(url)
            if subtitles:
                st.info(f"ğŸ“ Found {len(subtitles)} subtitle file(s)")
            else:
                st.info("ğŸ“ No subtitles available for this video")
        
        # ä½¿ç”¨yt-dlpè·å–æœ€ä½³è§†é¢‘æµURLï¼Œç„¶åç”¨ffmpegå¤„ç†
        with st.spinner('Getting video stream URL...'):
            cmd = [
                # 'C:\\Users\\PDLP-013-Eric\\Anaconda3\\envs\\video\\python.exe', '-m', 'yt_dlp',
                'python', '-m', 'yt_dlp',
                '-f', 'best[height<=720]',  # é€‰æ‹©720pä»¥ä¸‹çš„è§†é¢‘æµ
                '--get-url',
                '--no-playlist',
                url
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            if result.returncode != 0:
                raise Exception(f"è·å–è§†é¢‘æµURLå¤±è´¥: {result.stderr}")
            
            stream_url = result.stdout.strip()
            if not stream_url:
                raise Exception("æ— æ³•è·å–è§†é¢‘æµURL")
        
        # ä½¿ç”¨ffmpegä»æµURLä¸­æå–å¸§
        with st.spinner(f'Processing video: {title}...'):
            # æ ¹æ®è§†é¢‘é•¿åº¦å†³å®šé‡‡æ ·ç‡
            if duration <= 30:
                fps_filter = 'fps=2'  # çŸ­è§†é¢‘ï¼šæ¯ç§’2å¸§
                max_frames = min(60, int(duration * 2))  # æœ€å¤š60å¸§
            elif duration <= 120:
                fps_filter = 'fps=1'  # ä¸­ç­‰è§†é¢‘ï¼šæ¯ç§’1å¸§
                max_frames = min(120, int(duration))  # æœ€å¤š120å¸§
            else:
                fps_filter = 'fps=1'  # é•¿è§†é¢‘ï¼šæ¯ç§’1å¸§ï¼Œä¸è®¾ç½®ä¸Šé™
                max_frames = int(duration)  # æ ¹æ®æ—¶é•¿åŠ¨æ€è®¾ç½®
            
            # è·å–ffmpegçš„å®Œæ•´è·¯å¾„
            ffmpeg_path = imageio_ffmpeg.get_ffmpeg_exe()
            cmd = [
                ffmpeg_path,
                '-loglevel', 'error',  # åªæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ï¼Œéšè—è­¦å‘Š
                '-i', stream_url,
                '-vf', fps_filter,
                '-f', 'image2pipe',
                '-vcodec', 'png',
                '-frames:v', str(max_frames),  # åŠ¨æ€è®¾ç½®å¸§æ•°
                '-'
            ]
            
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            
            frames = []
            frame_count = 0
            
            # ä½¿ç”¨æ›´ç®€å•çš„æ–¹æ³•è¯»å–PNGæ•°æ®
            try:
                # è¯»å–æ‰€æœ‰è¾“å‡ºæ•°æ®
                stdout_data, stderr_data = process.communicate(timeout=60)
                
                # éšè—ffmpegçš„stderrè¾“å‡ºï¼Œä¸æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
                # if stderr_data:
                #     st.warning(f"ffmpegè­¦å‘Š: {stderr_data.decode()[:200]}")
                
                if stdout_data:
                    # æŸ¥æ‰¾PNGæ–‡ä»¶å¤´
                    png_start = b'\x89PNG\r\n\x1a\n'
                    png_end = b'IEND\xaeB`\x82'
                    
                    data = stdout_data
                    start = 0
                    
                    while True:
                        # æŸ¥æ‰¾PNGå¼€å§‹æ ‡è®°
                        png_start_pos = data.find(png_start, start)
                        if png_start_pos == -1:
                            break
                        
                        # æŸ¥æ‰¾PNGç»“æŸæ ‡è®°
                        png_end_pos = data.find(png_end, png_start_pos)
                        if png_end_pos == -1:
                            break
                        
                        # æå–PNGæ•°æ®
                        png_data = data[png_start_pos:png_end_pos + len(png_end)]
                        
                        try:
                            img = Image.open(BytesIO(png_data))
                            frames.append(img)
                            frame_count += 1
                            
                            if frame_count >= max_frames:  # ä½¿ç”¨åŠ¨æ€å¸§æ•°é™åˆ¶
                                break
                                
                        except Exception as e:
                            pass
                        
                        start = png_end_pos + len(png_end)
                
            except subprocess.TimeoutExpired:
                process.kill()
                st.warning("Video processing timeout")
            except Exception as e:
                st.warning(f"Error processing video frames: {str(e)}")
        
        if frames:
            subtitle_info = ""
            if subtitles:
                subtitle_info = f" and {len(subtitles)} subtitle file(s)"
            st.success(f"ğŸ¬ Video processing completed: Extracted {len(frames)} frames{subtitle_info} from {title} (Duration: {duration:.1f}s)")
        else:
            st.warning("Failed to extract frames from video, please check if the link is valid or try another video")
        
        return {
            'frames': frames,
            'subtitles': subtitles,
            'title': title,
            'duration': duration
        }
        
    except Exception as e:
        st.error(f"Error processing video: {str(e)}")
        return []


def process_video_url(url):
    """å¤„ç†è§†é¢‘é“¾æ¥ - ä½¿ç”¨æµå¼å¤„ç†"""
    result = stream_video_frames(url)
    if isinstance(result, dict):
        return result['frames']
    return result


def load_upload_file_and_show():
    images, filenames = [], []
    # å¯¹æ¯ä¸ªåŠ å…¥çš„å›¾åƒè®°å½•æ˜¯å¦éœ€è¦æŒä¹…åŒ–åˆ°ç£ç›˜ï¼ˆæ™®é€šå›¾ç‰‡ï¼šTrueï¼›è§†é¢‘å¸§ï¼šFalseï¼‰
    persist_flags = []
    
    # è§†é¢‘å¸§å•ç‹¬å¤„ç†ï¼Œä¸æ·»åŠ åˆ°imagesåˆ—è¡¨ä¸­
    video_frames_for_ai = []
    if 'video_frames' in st.session_state and st.session_state.video_frames:
        video_frames_for_ai = st.session_state.video_frames.copy()
    
    # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
    if uploaded_files is not None:
        video_exts = {'.mp4', '.mov', '.avi', '.mkv', '.webm'}
        def is_video_file(name, mime_type):
            ext = os.path.splitext(name)[1].lower()
            return (mime_type and mime_type.startswith('video')) or (ext in video_exts)

        def extract_video_frames_to_pil(tmp_video_path, max_frames=None):
            cap = cv2.VideoCapture(tmp_video_path)
            if not cap.isOpened():
                return []
            total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            if total <= 0:
                total = 1
            if fps <= 0:
                fps = 1
            
            # æ™ºèƒ½å…³é”®å¸§é€‰æ‹©ç­–ç•¥
            if max_frames is None:
                # å®Œå…¨åŠ¨æ€é€‰æ‹©ï¼šæ ¹æ®è§†é¢‘é•¿åº¦å’Œå†…å®¹æ™ºèƒ½å†³å®š
                duration = total / fps
                
                if total <= 30:
                    # çŸ­è§†é¢‘ï¼šæŠ½å–æ‰€æœ‰å¸§
                    target_frames = total
                elif duration <= 5:
                    # 5ç§’å†…ï¼šæ¯0.1ç§’ä¸€å¸§
                    target_frames = min(total, int(duration * 10))
                elif duration <= 30:
                    # 30ç§’å†…ï¼šæ¯0.2ç§’ä¸€å¸§
                    target_frames = min(total, int(duration * 5))
                elif duration <= 120:
                    # 2åˆ†é’Ÿå†…ï¼šæ¯0.5ç§’ä¸€å¸§
                    target_frames = min(total, int(duration * 2))
                else:
                    # é•¿è§†é¢‘ï¼šæ¯1ç§’ä¸€å¸§ï¼Œä¸è®¾ç½®ä¸Šé™
                    target_frames = int(duration)
                
                # ä½¿ç”¨æ™ºèƒ½é‡‡æ ·é€‰æ‹©å…³é”®å¸§
                if target_frames >= total:
                    # æŠ½å–æ‰€æœ‰å¸§
                    frames = []
                    while True:
                        ok, frame = cap.read()
                        if not ok or frame is None:
                            break
                        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                        frames.append(Image.fromarray(rgb))
                else:
                    # æ™ºèƒ½å…³é”®å¸§é€‰æ‹©ï¼šé€‰æ‹©å˜åŒ–æœ€å¤§çš„å¸§
                    frames = []
                    frame_indices = []
                    
                    # å…ˆå‡åŒ€é‡‡æ ·å€™é€‰å¸§
                    candidate_indices = np.linspace(0, total - 1, min(target_frames * 3, total), dtype=int)
                    
                    # è®¡ç®—å¸§é—´å·®å¼‚ï¼Œé€‰æ‹©å˜åŒ–æœ€å¤§çš„å¸§
                    prev_frame = None
                    frame_diffs = []
                    
                    for idx in candidate_indices:
                        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
                        ok, frame = cap.read()
                        if ok and frame is not None:
                            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                            if prev_frame is not None:
                                diff = cv2.absdiff(gray, prev_frame)
                                frame_diffs.append((idx, np.mean(diff)))
                            prev_frame = gray
                    
                    # é€‰æ‹©å·®å¼‚æœ€å¤§çš„å¸§
                    frame_diffs.sort(key=lambda x: x[1], reverse=True)
                    selected_indices = [x[0] for x in frame_diffs[:target_frames]]
                    selected_indices.sort()
                    
                    # æå–é€‰ä¸­çš„å¸§
                    for idx in selected_indices:
                        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
                        ok, frame = cap.read()
                        if ok and frame is not None:
                            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                            frames.append(Image.fromarray(rgb))
            else:
                # å¦‚æœæŒ‡å®šäº†max_framesï¼Œä½¿ç”¨å‡åŒ€é‡‡æ ·
                n = max(1, min(max_frames, total))
                ids = np.linspace(0, total - 1, n, dtype=np.int32)
                frames = []
                for fid in ids:
                    cap.set(cv2.CAP_PROP_POS_FRAMES, int(fid))
                    ok, frame = cap.read()
                    if ok and frame is not None:
                        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                        frames.append(Image.fromarray(rgb))
            cap.release()
            return frames

        # è®¡ç®—å½“å‰ä¼šè¯ä¸­å·²ä½¿ç”¨çš„å›¾ç‰‡é…é¢ï¼ˆç”¨æˆ·ä¸Šä¼ çš„å›¾åƒ/å¸§ï¼‰
        try:
            used_images = 0
            for m in st.session_state.get('messages', []):
                if m.get('role') == 'user' and 'image' in m:
                    used_images += len(m['image'])
        except Exception:
            used_images = 0

        for file in uploaded_files:
            file_bytes_raw = file.read()
            if is_video_file(getattr(file, 'name', ''), getattr(file, 'type', '')):
                # ä½¿ç”¨ç³»ç»Ÿä¸´æ—¶æ–‡ä»¶è¿›è¡ŒæŠ½å¸§ï¼Œæ–‡ä»¶ä¼šåœ¨å…³é—­åè‡ªåŠ¨åˆ é™¤ï¼Œä¸è½ç›˜åˆ°é¡¹ç›®ç›®å½•
                with tempfile.NamedTemporaryFile(suffix=os.path.splitext(getattr(file, 'name', 'video.mp4'))[1] or '.mp4', delete=True) as tf:
                    tf.write(file_bytes_raw)
                    tf.flush()
                    
                    # è·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯
                    cap = cv2.VideoCapture(tf.name)
                    if cap.isOpened():
                        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                        fps = cap.get(cv2.CAP_PROP_FPS)
                        duration = total_frames / fps if fps > 0 else 0
                        cap.release()
                    else:
                        total_frames = 1
                        fps = 1
                        duration = 0
                    
                    # å®Œå…¨åŠ¨æ€çš„å…³é”®å¸§æŠ½å–ï¼šä¸å—å›¾åƒé…é¢é™åˆ¶
                    frames = extract_video_frames_to_pil(tf.name, max_frames=None)
                    
                    # æ˜¾ç¤ºæŠ½å–ä¿¡æ¯
                    if len(frames) == total_frames:
                        st.info(f"ğŸ¬ Short video detected: Extracted all {total_frames} frames (Duration: {duration:.1f}s)")
                    else:
                        st.info(f"ğŸ¬ Smart keyframe extraction: Selected {len(frames)} keyframes from {total_frames} frames (Duration: {duration:.1f}s)")
                        
                images.extend(frames)
                persist_flags.extend([False] * len(frames))
                # ä¸è®°å½•è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå®Œå…¨åœ¨ä¸´æ—¶æ–‡ä»¶ä¸­å¤„ç†
            else:
                file_bytes = np.asarray(bytearray(file_bytes_raw), dtype=np.uint8)
                img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
                if img is None:
                    continue
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                img = Image.fromarray(img)
                images.append(img)
                persist_flags.append(True)
        # åªæ˜¾ç¤ºä¸Šä¼ çš„æ–‡ä»¶ï¼Œä¸æ˜¾ç¤ºYouTubeè§†é¢‘å¸§é¢„è§ˆ
        display_images = []
        display_persist_flags = []
        
        # åˆ†ç¦»ä¸Šä¼ æ–‡ä»¶å’ŒYouTubeè§†é¢‘å¸§
        for i, (image, to_persist) in enumerate(zip(images, persist_flags)):
            if to_persist:  # åªæ˜¾ç¤ºéœ€è¦æŒä¹…åŒ–çš„å›¾ç‰‡ï¼ˆä¸Šä¼ çš„æ–‡ä»¶ï¼‰
                display_images.append(image)
                display_persist_flags.append(to_persist)
        
        if display_images:
            with upload_image_preview.container():
                Library(display_images)
        
        # ä»…æŒä¹…åŒ–æ™®é€šä¸Šä¼ å›¾ç‰‡ï¼›è§†é¢‘å¸§ä¸è½ç›˜
        for image, to_persist in zip(images, persist_flags):
            if not to_persist:
                continue
            t = datetime.datetime.now()
            img_hash = hashlib.md5(image.tobytes()).hexdigest()
            filename = os.path.join(LOGDIR, 'serve_images', f'{t.year}-{t.month:02d}-{t.day:02d}', f'{img_hash}.jpg')
            filenames.append(filename)
            if not os.path.isfile(filename):
                os.makedirs(os.path.dirname(filename), exist_ok=True)
                image.save(filename)
    return images, filenames


def get_selected_worker_ip():
    if use_chatgpt:
        return chatgpt_worker_url
    
    ret = requests.post(controller_url + '/get_worker_address',
            json={'model': selected_model})
    worker_addr = ret.json()['address']
    return worker_addr


def save_chat_history():
    messages = st.session_state.messages
    new_messages = []
    for message in messages:
        new_message = {'role': message['role'], 'content': message['content']}
        if 'filenames' in message:
            new_message['filenames'] = message['filenames']
        new_messages.append(new_message)
    if len(new_messages) > 0:
        fout = open(get_conv_log_filename(), 'a')
        data = {
            'type': 'chat',
            'model': selected_model,
            'messages': new_messages,
        }
        fout.write(json.dumps(data, ensure_ascii=False) + '\n')
        fout.close()


def generate_response(messages):
    # ç»„è£…æ¶ˆæ¯
    base_messages = [{'role': 'system', 'content': system_message_default + '\n\n' + persona_rec}]
    last_user_index = -1
    for idx, message in enumerate(messages):
        if message['role'] == 'user':
            last_user_index = idx
        # å…ˆæŒ‰åŸæ ·æ‹·è´ï¼Œå›¾ç‰‡ç¨åå¤„ç†
        if message['role'] == 'user':
            base_messages.append({'role': 'user', 'content': message['content']})
        else:
            base_messages.append({'role': 'assistant', 'content': message['content']})

    images = []
    if last_user_index != -1 and 'image' in messages[last_user_index] and messages[last_user_index]['image']:
        images = messages[last_user_index]['image']

    worker_addr = get_selected_worker_ip()
    headers = {'User-Agent': 'InternVL-Chat Client'}
    placeholder = st.empty()

    # è‹¥å¤šå¼ å›¾ï¼šæ‰¹é‡å¤„ç†æ‰€æœ‰å¸§ï¼Œæ±‡æ€»åˆ†æç»“æœåä¸€æ¬¡æ€§å±•ç¤º
    if len(images) > 1:
        # æ˜¾ç¤ºå¤„ç†è¿›åº¦ï¼Œä½†ä¸æ˜¾ç¤ºå…·ä½“åˆ†æå†…å®¹
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        frame_analyses = []
        total_frames = len(images)
        
        for i, img in enumerate(images, start=1):
            # æ›´æ–°è¿›åº¦æ˜¾ç¤º
            progress = i / total_frames
            progress_bar.progress(progress)
            if lan == 'English':
                percentage = (i / total_frames) * 100
                status_text.text(f"Analyzing frame {i}/{total_frames} ({percentage:.2f}%)...")
            else:
                percentage = (i / total_frames) * 100
                status_text.text(f"æ­£åœ¨åˆ†æç¬¬ {i}/{total_frames} å¸§ ({percentage:.2f}%)...")

            # ä¸ºå½“å‰å›¾ç‰‡æ„é€ æ¶ˆæ¯ï¼šä»…æ›¿æ¢"æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯"
            enforced_hint = "è¯·åªæ ¹æ®å½“å‰å›¾åƒè¿›è¡Œè¯¦ç»†æè¿°ï¼Œä¸è¦æ¨æ–­è§†é¢‘æ•´ä½“ä¿¡æ¯ã€‚"
            last_user_content = messages[last_user_index]['content']
            final_user_content = f"{last_user_content}\n\n{enforced_hint}"
            per_image_messages = base_messages[:-1] + [
                {'role': 'user', 'content': final_user_content, 'image': [pil_image_to_base64(img)]}
            ]

            pload = {
                'model': selected_model,
                'prompt': per_image_messages,
                'temperature': float(temperature),
                'top_p': float(top_p),
                'max_new_tokens': max_length,
                'max_input_tiles': max_input_tiles,
                'repetition_penalty': float(repetition_penalty),
            }

            current_output_text = ''
            try:
                response = requests.post(
                    worker_addr + '/worker_generate_stream',
                    headers=headers, json=pload, stream=True, timeout=3600)
                for chunk in response.iter_lines(decode_unicode=True, delimiter=b'\0'):
                    if chunk:
                        data = json.loads(chunk.decode())
                        if data['error_code'] == 0:
                            current_output_text = data['text']
                        else:
                            current_output_text = data['text'] + f" (error_code: {data['error_code']})"
                
                # æ•°å­¦ç¬¦å·æ¸…ç†
                if ('\\[' in current_output_text and '\\]' in current_output_text) or ('\\(' in current_output_text and '\\)' in current_output_text):
                    current_output_text = current_output_text.replace('\\[', '$').replace('\\]', '$').replace('\\(', '$').replace('\\)', '$')
                
                frame_analyses.append(current_output_text)
                
            except requests.exceptions.RequestException:
                frame_analyses.append(server_error_msg)
        
        # æ¸…é™¤è¿›åº¦æ˜¾ç¤º
        progress_bar.empty()
        status_text.empty()
        
        # æ˜¾ç¤ºæ­£åœ¨æ±‡æ€»åˆ†æç»“æœçš„æç¤º
        if lan == 'English':
            placeholder.markdown("ğŸ”„ Summarizing analysis results from all frames...")
        else:
            placeholder.markdown("ğŸ”„ æ­£åœ¨æ±‡æ€»æ‰€æœ‰å¸§çš„åˆ†æç»“æœ...")
        
        # å°†æ‰€æœ‰å¸§åˆ†æç»“æœå‘é€ç»™æ¨¡å‹è¿›è¡Œæ±‡æ€»
        if lan == 'English':
            summary_prompt = f"""Please provide a comprehensive video analysis summary based on the following analysis results from {total_frames} video frames.

Frame analysis results:
"""
            for i, analysis in enumerate(frame_analyses, 1):
                summary_prompt += f"\nFrame {i} analysis:\n{analysis}\n"

            summary_prompt += f"""

Please provide a comprehensive video analysis summary including:
1. Overall content and theme of the video
2. Changes in main scenes and objects
3. Key events or action sequences
4. Overall visual style and atmosphere

Please answer in English, keep it concise and highlight key points."""
        else:
            summary_prompt = f"""è¯·åŸºäºä»¥ä¸‹{total_frames}å¸§è§†é¢‘çš„åˆ†æç»“æœï¼Œæä¾›ä¸€ä¸ªç»¼åˆçš„è§†é¢‘åˆ†ææ€»ç»“ã€‚

è§†é¢‘å¸§åˆ†æç»“æœï¼š
"""
            for i, analysis in enumerate(frame_analyses, 1):
                summary_prompt += f"\nå¸§ {i} åˆ†æï¼š\n{analysis}\n"

            summary_prompt += f"""

è¯·æä¾›ä¸€ä¸ªç»¼åˆçš„è§†é¢‘åˆ†ææ€»ç»“ï¼ŒåŒ…æ‹¬ï¼š
1. è§†é¢‘çš„æ•´ä½“å†…å®¹å’Œä¸»é¢˜
2. ä¸»è¦åœºæ™¯å’Œå¯¹è±¡çš„å˜åŒ–
3. å…³é”®äº‹ä»¶æˆ–åŠ¨ä½œåºåˆ—
4. æ•´ä½“è§†è§‰é£æ ¼å’Œæ°›å›´

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå†…å®¹è¦ç®€æ´æ˜äº†ï¼Œçªå‡ºé‡ç‚¹ã€‚"""

        summary_messages = base_messages[:-1] + [
            {'role': 'user', 'content': summary_prompt}
        ]
        
        summary_pload = {
            'model': selected_model,
            'prompt': summary_messages,
            'temperature': float(temperature),
            'top_p': float(top_p),
            'max_new_tokens': max_length,
            'max_input_tiles': max_input_tiles,
            'repetition_penalty': float(repetition_penalty),
        }
        
        final_summary = ''
        try:
            response = requests.post(
                worker_addr + '/worker_generate_stream',
                headers=headers, json=summary_pload, stream=True, timeout=3600)
            for chunk in response.iter_lines(decode_unicode=True, delimiter=b'\0'):
                if chunk:
                    data = json.loads(chunk.decode())
                    if data['error_code'] == 0:
                        final_summary = data['text']
                        placeholder.markdown(final_summary + 'â–Œ')
                    else:
                        final_summary = data['text'] + f" (error_code: {data['error_code']})"
                        placeholder.markdown(final_summary)
            
            # æ•°å­¦ç¬¦å·æ¸…ç†
            if ('\\[' in final_summary and '\\]' in final_summary) or ('\\(' in final_summary and '\\)' in final_summary):
                final_summary = final_summary.replace('\\[', '$').replace('\\]', '$').replace('\\(', '$').replace('\\)', '$')
                
        except requests.exceptions.RequestException:
            final_summary = server_error_msg
            placeholder.markdown(final_summary)
        
        placeholder.markdown(final_summary)
        return final_summary
    else:
        # å•å›¾æˆ–æ— å›¾ï¼šæ²¿ç”¨åŸå•è¯·æ±‚é€»è¾‘
        # æŠŠæœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯çš„å›¾ç‰‡ï¼ˆè‹¥æœ‰ï¼‰åŠ å…¥
        enforced_hint = "è¯·åªæ ¹æ®å½“å‰å›¾åƒè¿›è¡Œè¯¦ç»†æè¿°ï¼Œä¸è¦æ¨æ–­è§†é¢‘æ•´ä½“ä¿¡æ¯ã€‚"
        last_user_content = messages[last_user_index]['content'] if last_user_index != -1 else ''
        final_user_content = f"{last_user_content}\n\n{enforced_hint}" if last_user_index != -1 else ''
        if len(images) == 1 and last_user_index != -1:
            send_messages = base_messages[:-1] + [
                {'role': 'user', 'content': final_user_content, 'image': [pil_image_to_base64(images[0])]}
            ]
        else:
            send_messages = base_messages

        pload = {
            'model': selected_model,
            'prompt': send_messages,
            'temperature': float(temperature),
            'top_p': float(top_p),
            'max_new_tokens': max_length,
            'max_input_tiles': max_input_tiles,
            'repetition_penalty': float(repetition_penalty),
        }
        output = ''
        try:
            response = requests.post(worker_addr + '/worker_generate_stream',
                                     headers=headers, json=pload, stream=True, timeout=3600)
            for chunk in response.iter_lines(decode_unicode=True, delimiter=b'\0'):
                if chunk:
                    data = json.loads(chunk.decode())
                    if data['error_code'] == 0:
                        output = data['text']
                        if '4B' in selected_model and 'ï¿½' in output[-2:]:
                            output = output.replace('ï¿½', '')
                            break
                        placeholder.markdown(output + 'â–Œ')
                    else:
                        output = data['text'] + f" (error_code: {data['error_code']})"
                        placeholder.markdown(output)
            if ('\\[' in output and '\\]' in output) or ('\\(' in output and '\\)' in output):
                output = output.replace('\\[', '$').replace('\\]', '$').replace('\\(', '$').replace('\\)', '$')
            placeholder.markdown(output)
        except requests.exceptions.RequestException:
            placeholder.markdown(server_error_msg)
        return output


def pil_image_to_base64(image):
    buffered = BytesIO()
    image.save(buffered, format='PNG')
    return base64.b64encode(buffered.getvalue()).decode('utf-8')


def clear_chat_history():
    st.session_state.messages = []
    # æ¸…é™¤è§†é¢‘å¸§å’Œå­—å¹•
    if 'video_frames' in st.session_state:
        st.session_state.video_frames = []
    if 'video_url' in st.session_state:
        st.session_state.video_url = ''
    if 'video_subtitles' in st.session_state:
        del st.session_state.video_subtitles
    if 'video_title' in st.session_state:
        del st.session_state.video_title


def clear_file_uploader():
    st.session_state.uploader_key += 1
    st.rerun()


def combined_func(func_list):
    for func in func_list:
        func()


def show_one_or_multiple_images(message, total_image_num, is_input=True):
    if 'image' in message:
        if is_input:
            total_image_num = total_image_num + len(message['image'])
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è§†é¢‘å¸§
            video_frames_count = 0
            regular_images_count = 0
            
            if 'video_frames' in st.session_state and st.session_state.video_frames:
                video_frames_count = len(st.session_state.video_frames)
                regular_images_count = len(message['image']) - video_frames_count
            else:
                regular_images_count = len(message['image'])
            
            if lan == 'English':
                if video_frames_count > 0 and regular_images_count > 0:
                    label = f"(In this conversation, {regular_images_count} image(s) uploaded, {video_frames_count} frames from video processed, {total_image_num} total)"
                elif video_frames_count > 0:
                    label = f"(In this conversation, {video_frames_count} frames from video processed, {total_image_num} total)"
                elif regular_images_count == 1 and total_image_num == 1:
                    label = f"(In this conversation, {regular_images_count} image was uploaded, {total_image_num} image in total)"
                elif regular_images_count == 1 and total_image_num > 1:
                    label = f"(In this conversation, {regular_images_count} image was uploaded, {total_image_num} images in total)"
                else:
                    label = f"(In this conversation, {regular_images_count} images were uploaded, {total_image_num} images in total)"
            else:
                if video_frames_count > 0 and regular_images_count > 0:
                    label = f"(åœ¨æœ¬æ¬¡å¯¹è¯ä¸­ï¼Œä¸Šä¼ äº†{regular_images_count}å¼ å›¾ç‰‡ï¼Œå¤„ç†äº†{video_frames_count}å¸§è§†é¢‘ï¼Œæ€»å…±{total_image_num}å¼ )"
                elif video_frames_count > 0:
                    label = f"(åœ¨æœ¬æ¬¡å¯¹è¯ä¸­ï¼Œå¤„ç†äº†{video_frames_count}å¸§è§†é¢‘ï¼Œæ€»å…±{total_image_num}å¼ )"
                else:
                    label = f"(åœ¨æœ¬æ¬¡å¯¹è¯ä¸­ï¼Œä¸Šä¼ äº†{regular_images_count}å¼ å›¾ç‰‡ï¼Œæ€»å…±ä¸Šä¼ äº†{total_image_num}å¼ å›¾ç‰‡)"
        
        # æ˜¾ç¤ºèŠå¤©è®°å½•ä¸­çš„å›¾ç‰‡ï¼ˆç°åœ¨åªåŒ…å«ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡ï¼‰
        if message['image']:
            upload_image_preview = st.empty()
            with upload_image_preview.container():
                Library(message['image'])
        
        # å¦‚æœæœ‰è§†é¢‘å¸§è¢«å¤„ç†ï¼Œæ˜¾ç¤ºæç¤ºä¿¡æ¯
        if 'video_frames' in st.session_state and st.session_state.video_frames:
            video_frames_count = len(st.session_state.video_frames)
            subtitle_info = ""
            if 'video_subtitles' in st.session_state and st.session_state.video_subtitles:
                subtitle_count = len(st.session_state.video_subtitles)
                if lan == 'English':
                    subtitle_info = f" and {subtitle_count} subtitle file(s)"
                else:
                    subtitle_info = f" å’Œ {subtitle_count} ä¸ªå­—å¹•æ–‡ä»¶"
            
            if lan == 'English':
                st.info(f"ğŸ¥ Video frames ({video_frames_count} frames){subtitle_info} are being processed in the background")
            else:
                st.info(f"ğŸ¥ è§†é¢‘å¸§ï¼ˆ{video_frames_count}å¸§ï¼‰{subtitle_info}æ­£åœ¨åå°å¤„ç†ä¸­")
        
        # åªåœ¨æœ‰ä¸Šä¼ çš„å›¾ç‰‡æ—¶æ˜¾ç¤ºæ ‡ç­¾ï¼Œçº¯è§†é¢‘å¤„ç†æ—¶ä¸æ˜¾ç¤º
        if is_input and regular_images_count > 0:
            st.markdown(label)


def find_bounding_boxes(response):
    pattern = re.compile(r'<ref>\s*(.*?)\s*</ref>\s*<box>\s*(\[\[.*?\]\])\s*</box>')
    matches = pattern.findall(response)
    results = []
    for match in matches:
        results.append((match[0], eval(match[1])))
    returned_image = None
    for message in st.session_state.messages:
        if message['role'] == 'user' and 'image' in message and len(message['image']) > 0:
            last_image = message['image'][-1]
            width, height = last_image.size
            returned_image = last_image.copy()
            draw = ImageDraw.Draw(returned_image)
    for result in results:
        line_width = max(1, int(min(width, height) / 200))
        random_color = (random.randint(0, 128), random.randint(0, 128), random.randint(0, 128))
        category_name, coordinates = result
        coordinates = [(float(x[0]) / 1000, float(x[1]) / 1000, float(x[2]) / 1000, float(x[3]) / 1000) for x in coordinates]
        coordinates = [(int(x[0] * width), int(x[1] * height), int(x[2] * width), int(x[3] * height)) for x in coordinates]
        for box in coordinates:
            draw.rectangle(box, outline=random_color, width=line_width)
            font = ImageFont.truetype('static/SimHei.ttf', int(20 * line_width / 2))
            text_size = font.getbbox(category_name)
            text_width, text_height = text_size[2] - text_size[0], text_size[3] - text_size[1]
            text_position = (box[0], max(0, box[1] - text_height))
            draw.rectangle(
                [text_position, (text_position[0] + text_width, text_position[1] + text_height)],
                fill=random_color
            )
            draw.text(text_position, category_name, fill='white', font=font)
    return returned_image if len(matches) > 0 else None


def query_image_generation(response, sd_worker_url, timeout=15):
    sd_worker_url = f'{sd_worker_url}/generate_image/'
    pattern = r'```drawing-instruction\n(.*?)\n```'
    match = re.search(pattern, response, re.DOTALL)
    if match:
        payload = {'caption': match.group(1)}
        print('drawing-instruction:', payload)
        response = requests.post(sd_worker_url, json=payload, timeout=timeout)
        response.raise_for_status()
        image = Image.open(BytesIO(response.content))
        return image
    else:
        return None


def regenerate():
    st.session_state.messages = st.session_state.messages[:-1]
    st.rerun()


logo_code = """
<svg width="600" height="120" xmlns="http://www.w3.org/2000/svg">
  <defs>
    <linearGradient id="gradient1" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color: #1e3a8a; stop-opacity: 1" />
      <stop offset="100%" style="stop-color: #3b82f6; stop-opacity: 1" />
    </linearGradient>
    <linearGradient id="gradient2" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color: #f97316; stop-opacity: 1" />
      <stop offset="100%" style="stop-color: #fbbf24; stop-opacity: 1" />
    </linearGradient>
  </defs>
  <!-- Curved swoosh element -->
  <path d="M 20 50 Q 200 15 300 25 Q 400 35 580 50" stroke="url(#gradient2)" stroke-width="4" fill="none" />
  <!-- Main brand text -->
  <text x="150" y="80" font-size="60" font-weight="bold" fill="url(#gradient1)" style="font-family: Arial, sans-serif; font-style: italic;">
    PacDent
  </text>
  <!-- Registered trademark symbol -->
  <text x="300" y="60" font-size="20" fill="url(#gradient1)" style="font-family: Arial, sans-serif;">Â®</text>
  <!-- Tagline -->
  <text x="150" y="105" font-size="20" fill="#6b7280" style="font-family: Arial, sans-serif;">
    Passion for Excellence
  </text>
</svg>
"""

# App title
st.set_page_config(
    page_title='Pac-Dent MediaMind',
    page_icon='static/pac-dent-logo.png',
    layout='wide',
    initial_sidebar_state='expanded'
)

if 'uploader_key' not in st.session_state:
    st.session_state.uploader_key = 0

system_message_default = 'æˆ‘æ˜¯ Pac-Dent MediaMindï¼Œä¸€ä¸ªä¸“ä¸šçš„AIåª’ä½“åˆ†æå’Œç†è§£å¹³å°ï¼Œä¸“æ³¨äºæä¾›é«˜è´¨é‡çš„åª’ä½“å†…å®¹åˆ†æå’Œæ™ºèƒ½å¤„ç†æœåŠ¡ã€‚'

system_message_editable = 'You are an AI system that summarizes video content based on visual and textual input. ### Task: You will be given: - A series of key video frames (images), representing important scenes from a video. - The corresponding subtitles or transcript (in English or translated to English). Analyze both the visual and textual content together to generate an accurate and concise summary of the video\'s content. Identify key themes, events, people, and topics. ### Instructions: 1. Carefully examine the visual content of the images to understand scenes, people, objects, and context. 2. Read and analyze the subtitles to capture dialogue, narration, and progression. 3. Combine both modalities to understand the full message of the video. 4. Avoid copying subtitles word-for-word. Instead, paraphrase and synthesize meaningfully. 5. Output a summary in 1â€“2 paragraphs, or bullet points if the video covers multiple segments. 6. Use a neutral and informative tone. ### Output: Return only the summary. Do not include image captions or metadata.'


# Replicate Credentials
with st.sidebar:
    model_list = get_model_list()
    # å›ºå®šä½¿ç”¨ä¸­æ–‡ç•Œé¢ï¼Œéšè—è¯­è¨€é€‰æ‹©
    lan = 'English'
    if lan == 'English':
        # st.logo(logo_code, link='https://github.com/OpenGVLab/InternVL', icon_image=logo_code)
        # æ¨¡å‹é€‰æ‹©å·²éšè—ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
        selected_model = model_list[0] if model_list else 'default'
        
        # æ·»åŠ è‡ªå®šä¹‰ä»£ç†æ ‡é¢˜
        st.markdown("### ğŸ¯ Customize Your Agent Here!")
        
        with st.expander('ğŸ¤– System Prompt'):
            persona_rec = st.text_area('System Prompt', value=system_message_editable,
                                       help='System prompt is a pre-defined message used to instruct the assistant at the beginning of a conversation.',
                                       height=200)
        # Advanced Options å·²éšè—ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°
        temperature = 0.7
        top_p = 0.95
        repetition_penalty = 1.1
        max_length = 1024
        max_input_tiles = 12
        # è§†é¢‘é“¾æ¥è¾“å…¥
        st.subheader('ğŸ¥ Enter a video link')
        # åˆå§‹åŒ–session state
        if 'video_url' not in st.session_state:
            st.session_state.video_url = ''
        
        video_url = st.text_input('Video Link', 
                                 value=st.session_state.video_url,
                                 placeholder='Paste your Video Link here',
                                 help='Enter a video link, then click the button to process the video', 
                                 key='video_url_input',
                                 label_visibility="visible")
        
        # æ›´æ–°session state
        st.session_state.video_url = video_url
        
        # è§†é¢‘å¤„ç†æŒ‰é’®å’Œæ¸…ç©ºæŒ‰é’®å¹¶æ’
        col1, col2 = st.columns([3, 1])
        with col1:
            if st.button('ğŸ¬ Process Video', type='primary'):
                if video_url and video_url.strip():
                    if is_video_url(video_url.strip()):
                        with st.spinner('Processing video...'):
                            # æ¸…ç©ºä¸Šä¸€æ¬¡çš„è§†é¢‘è®°å½•
                            st.session_state.video_frames = []
                            if 'video_subtitles' in st.session_state:
                                del st.session_state.video_subtitles
                            if 'video_title' in st.session_state:
                                del st.session_state.video_title
                            
                            result = stream_video_frames(video_url.strip())
                            if result and isinstance(result, dict) and result['frames']:
                                # å°†è§†é¢‘å¸§æ·»åŠ åˆ°session state
                                st.session_state.video_frames = result['frames']
                                
                                # å­˜å‚¨å­—å¹•ä¿¡æ¯
                                if result['subtitles']:
                                    st.session_state.video_subtitles = result['subtitles']
                                    st.session_state.video_title = result['title']
                                
                                subtitle_info = f" and {len(result['subtitles'])} subtitle file(s)" if result['subtitles'] else ""
                                # æ˜¾ç¤ºå­—å¹•é¢„è§ˆ
                                if result['subtitles']:
                                    with st.expander("ğŸ“ Subtitle Preview", expanded=True):
                                        for i, subtitle in enumerate(result['subtitles']):
                                            st.write(f"**Subtitle {i+1}:**")
                                            # è§£æå­—å¹•å†…å®¹å¹¶æ˜¾ç¤ºçº¯æ–‡æœ¬
                                            content = subtitle['content']
                                            try:
                                                # å°è¯•è§£æJSONæ ¼å¼å­—å¹•
                                                import json
                                                data = json.loads(content)
                                                text_segments = []
                                                for event in data.get('events', []):
                                                    if 'segs' in event:
                                                        for seg in event['segs']:
                                                            if 'utf8' in seg and seg['utf8'].strip():
                                                                text_segments.append(seg['utf8'].strip())
                                                display_text = ' '.join(text_segments)
                                            except:
                                                # å¦‚æœä¸æ˜¯JSONï¼ŒæŒ‰VTTæ ¼å¼å¤„ç†
                                                lines = content.split('\n')
                                                buf = []
                                                time = ''
                                                for line in lines:
                                                    if '-->' in line:
                                                        time = line.strip()
                                                    elif line and not line.startswith('WEBVTT') and not line.isdigit():
                                                        buf.append(f"{time} | {line.strip()}")
                                                display_text = "\n".join(buf)
                                            st.text_area(f"Subtitle Text {i+1}:", display_text, height=150, key=f"preview_text_{i}")
                            else:
                                st.error("Failed to process video")
                    else:
                        st.warning("Please enter a valid video link")
                else:
                    st.warning("Please enter a video link")
        
        with col2:
            # åªè¦æœ‰è§†é¢‘URLè¾“å…¥å°±æ˜¾ç¤ºæ¸…ç©ºæŒ‰é’®ï¼Œå…è®¸éšæ—¶å–æ¶ˆå¤„ç†
            if video_url and video_url.strip():
                if st.button('ğŸ—‘ï¸ Clear', help='Clear video URL and stop processing'):
                    st.session_state.video_frames = []
                    st.session_state.video_url = ''
                    if 'video_subtitles' in st.session_state:
                        del st.session_state.video_subtitles
                    if 'video_title' in st.session_state:
                        del st.session_state.video_title
        
        upload_image_preview = st.empty()
        uploaded_files = st.file_uploader('Upload files', accept_multiple_files=True,
                                          type=['png', 'jpg', 'jpeg', 'webp', 'mp4', 'mov', 'avi', 'mkv', 'webm'],
                                          help = f'You can upload multiple images (up to {max_image_limit}) or a single video.',
                                          key=f'uploader_{st.session_state.uploader_key}',
                                          on_change=st.rerun)
        uploaded_pil_images, save_filenames = load_upload_file_and_show()
        
        # å­—å¹•ä¿¡æ¯å·²éšè— - ä¸å†æ˜¾ç¤ºç»™ç”¨æˆ·
        # if 'video_subtitles' in st.session_state and st.session_state.video_subtitles:
        #     with st.expander('ğŸ“ Video Subtitles', expanded=True):
        #         for i, subtitle in enumerate(st.session_state.video_subtitles):
        #             st.write(f"**Subtitle File {i+1}:**")
        #             # æ˜¾ç¤ºå®Œæ•´çš„å­—å¹•å†…å®¹ï¼ˆåŒ…æ‹¬æ—¶é—´æˆ³ï¼‰
        #             st.text_area(f"Full Content {i+1}:", subtitle['content'], height=200, key=f"full_subtitle_{i}")
        #             
        #             # æå–å¹¶æ˜¾ç¤ºçº¯æ–‡æœ¬ç‰ˆæœ¬
        #             lines = subtitle['content'].split('\n')
        #             text_lines = [line for line in lines if line and not line.startswith('WEBVTT') and not '-->' in line and not line.isdigit()]
        #             subtitle_text = " ".join(text_lines)
        #             if subtitle_text.strip():
        #                 st.write("**Text Only:**")
        #                 st.text_area(f"Text Content {i+1}:", subtitle_text.strip(), height=100, key=f"text_subtitle_{i}")
        #             else:
        #                 st.write("No text content found in this subtitle file.")
    else:
        # æ¨¡å‹é€‰æ‹©å·²éšè—ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
        selected_model = model_list[0] if model_list else 'default'
        
        # æ·»åŠ è‡ªå®šä¹‰ä»£ç†æ ‡é¢˜
        st.markdown("### ğŸ¯ Customize Your Agent Here!")
        
        with st.expander('ğŸ¤– ç³»ç»Ÿæç¤º'):
            persona_rec = st.text_area('ç³»ç»Ÿæç¤º', value=system_message_editable,
                                       help='ç³»ç»Ÿæç¤ºæ˜¯åœ¨å¯¹è¯å¼€å§‹æ—¶ç”¨äºæŒ‡ç¤ºåŠ©æ‰‹çš„é¢„å®šä¹‰æ¶ˆæ¯ã€‚',
                                       height=200)
        # é«˜çº§é€‰é¡¹å·²éšè—ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°
        temperature = 0.7
        top_p = 0.95
        repetition_penalty = 1.1
        max_length = 1024
        max_input_tiles = 12
        
        # è§†é¢‘é“¾æ¥è¾“å…¥
        st.subheader('ğŸ¥ æˆ–è¾“å…¥è§†é¢‘é“¾æ¥')
        # åˆå§‹åŒ–session state
        if 'video_url' not in st.session_state:
            st.session_state.video_url = ''
        
        video_url = st.text_input('è§†é¢‘é“¾æ¥', 
                                 value=st.session_state.video_url,
                                 placeholder='https://www.youtube.com/watch?v=... æˆ– https://vimeo.com/... æˆ–ç›´æ¥è§†é¢‘æ–‡ä»¶é“¾æ¥',
                                 help='è¾“å…¥è§†é¢‘é“¾æ¥ï¼Œç„¶åç‚¹å‡»æŒ‰é’®å¤„ç†è§†é¢‘', 
                                 key='video_url_input',
                                 label_visibility="visible")
        
        # æ›´æ–°session state
        st.session_state.video_url = video_url
        
        # è§†é¢‘å¤„ç†æŒ‰é’®å’Œæ¸…ç©ºæŒ‰é’®å¹¶æ’
        col1, col2 = st.columns([3, 1])
        with col1:
            if st.button('ğŸ¬ å¤„ç†è§†é¢‘', type='primary'):
                if video_url and video_url.strip():
                    if is_video_url(video_url.strip()):
                        with st.spinner('Processing video...'):
                            # æ¸…ç©ºä¸Šä¸€æ¬¡çš„è§†é¢‘è®°å½•
                            st.session_state.video_frames = []
                            if 'video_subtitles' in st.session_state:
                                del st.session_state.video_subtitles
                            if 'video_title' in st.session_state:
                                del st.session_state.video_title
                            
                            result = stream_video_frames(video_url.strip())
                            if result and isinstance(result, dict) and result['frames']:
                                # å°†è§†é¢‘å¸§æ·»åŠ åˆ°session state
                                st.session_state.video_frames = result['frames']
                                
                                # å­˜å‚¨å­—å¹•ä¿¡æ¯
                                if result['subtitles']:
                                    st.session_state.video_subtitles = result['subtitles']
                                    st.session_state.video_title = result['title']
                                
                                subtitle_info = f" å’Œ {len(result['subtitles'])} ä¸ªå­—å¹•æ–‡ä»¶" if result['subtitles'] else ""
                                st.success(f"æˆåŠŸå¤„ç†è§†é¢‘ï¼Œæå–äº† {len(result['frames'])} å¸§{subtitle_info}")
                                
                                # æ˜¾ç¤ºå­—å¹•é¢„è§ˆ
                                if result['subtitles']:
                                    with st.expander("ğŸ“ å­—å¹•é¢„è§ˆ", expanded=True):
                                        for i, subtitle in enumerate(result['subtitles']):
                                            st.write(f"**å­—å¹• {i+1}:**")
                                            # è§£æå­—å¹•å†…å®¹å¹¶æ˜¾ç¤ºçº¯æ–‡æœ¬
                                            content = subtitle['content']
                                            try:
                                                # å°è¯•è§£æJSONæ ¼å¼å­—å¹•
                                                import json
                                                data = json.loads(content)
                                                text_segments = []
                                                for event in data.get('events', []):
                                                    if 'segs' in event:
                                                        for seg in event['segs']:
                                                            if 'utf8' in seg and seg['utf8'].strip():
                                                                text_segments.append(seg['utf8'].strip())
                                                display_text = ' '.join(text_segments)
                                            except:
                                                # å¦‚æœä¸æ˜¯JSONï¼ŒæŒ‰VTTæ ¼å¼å¤„ç†
                                                lines = content.split('\n')
                                                buf = []
                                                time = ''
                                                for line in lines:
                                                    if '-->' in line:
                                                        time = line.strip()
                                                    elif line and not line.startswith('WEBVTT') and not line.isdigit():
                                                        buf.append(f"{time} | {line.strip()}")
                                                display_text = "\n".join(buf)
                                            st.text_area(f"å­—å¹•æ–‡æœ¬ {i+1}:", display_text, height=150, key=f"preview_text_{i}")
                            else:
                                st.error("å¤„ç†è§†é¢‘å¤±è´¥")
                    else:
                        st.warning("Please enter a valid video link")
                else:
                    st.warning("Please enter a video link")
        
        with col2:
            # åªè¦æœ‰è§†é¢‘URLè¾“å…¥å°±æ˜¾ç¤ºæ¸…ç©ºæŒ‰é’®ï¼Œå…è®¸éšæ—¶å–æ¶ˆå¤„ç†
            if video_url and video_url.strip():
                if st.button('ğŸ—‘ï¸ æ¸…ç©º', help='æ¸…ç©ºè§†é¢‘é“¾æ¥å¹¶åœæ­¢å¤„ç†'):
                    st.session_state.video_frames = []
                    st.session_state.video_url = ''
                    if 'video_subtitles' in st.session_state:
                        del st.session_state.video_subtitles
                    if 'video_title' in st.session_state:
                        del st.session_state.video_title
        
        upload_image_preview = st.empty()
        uploaded_files = st.file_uploader('ä¸Šä¼ æ–‡ä»¶', accept_multiple_files=True,
                                          type=['png', 'jpg', 'jpeg', 'webp', 'mp4', 'mov', 'avi', 'mkv', 'webm'],
                                          help=f'ä½ å¯ä»¥ä¸Šä¼ å¤šå¼ å›¾åƒï¼ˆæœ€å¤š{max_image_limit}å¼ ï¼‰æˆ–è€…ä¸€ä¸ªè§†é¢‘ã€‚',
                                          key=f'uploader_{st.session_state.uploader_key}',
                                          on_change=st.rerun)
        uploaded_pil_images, save_filenames = load_upload_file_and_show()
        
        # å­—å¹•ä¿¡æ¯å·²éšè— - ä¸å†æ˜¾ç¤ºç»™ç”¨æˆ·
        # if 'video_subtitles' in st.session_state and st.session_state.video_subtitles:
        #     with st.expander('ğŸ“ è§†é¢‘å­—å¹•', expanded=True):
        #         for i, subtitle in enumerate(st.session_state.video_subtitles):
        #             st.write(f"**å­—å¹•æ–‡ä»¶ {i+1}:**")
        #             # æ˜¾ç¤ºå®Œæ•´çš„å­—å¹•å†…å®¹ï¼ˆåŒ…æ‹¬æ—¶é—´æˆ³ï¼‰
        #             st.text_area(f"å®Œæ•´å†…å®¹ {i+1}:", subtitle['content'], height=200, key=f"full_subtitle_{i}")
        #             
        #             # æå–å¹¶æ˜¾ç¤ºçº¯æ–‡æœ¬ç‰ˆæœ¬
        #             lines = subtitle['content'].split('\n')
        #             text_lines = [line for line in lines if line and not line.startswith('WEBVTT') and not '-->' in line and not line.isdigit()]
        #             subtitle_text = " ".join(text_lines)
        #             if subtitle_text.strip():
        #                 st.write("**çº¯æ–‡æœ¬ç‰ˆæœ¬:**")
        #                 st.text_area(f"æ–‡æœ¬å†…å®¹ {i+1}:", subtitle_text.strip(), height=100, key=f"text_subtitle_{i}")
        #             else:
        #                 st.write("æ­¤å­—å¹•æ–‡ä»¶ä¸­æœªæ‰¾åˆ°æ–‡æœ¬å†…å®¹ã€‚")

# Logo styling and hide menu
st.markdown("""
<style>
.logo-container {
    display: flex;
    justify-content: center;
    align-items: center;
    margin: 20px 0;
}

/* Hide the Streamlit menu button (three dots) */
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
header {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

if lan == 'English':
    st.markdown('<div class="logo-container">' + logo_code + '</div>', unsafe_allow_html=True)
    st.markdown('''
        <div style="text-align:center;">
            <p style="font-size:20px; color:gray;">An AI-Powered Media Analysis and Understanding Platform</p>
        </div>
    ''', unsafe_allow_html=True)
else:
    st.markdown('<div class="logo-container">' + logo_code + '</div>', unsafe_allow_html=True)
    st.markdown('''
        <div style="text-align:center;">
            <p style="font-size:20px; color:gray;">AIé©±åŠ¨çš„åª’ä½“åˆ†æå’Œç†è§£å¹³å°</p>
        </div>
    ''', unsafe_allow_html=True)


# Store LLM generated responses
if 'messages' not in st.session_state.keys():
    clear_chat_history()

# ç§»é™¤ç¤ºä¾‹å›¾ç‰‡å±•ç¤ºåŒºåŸŸ
gallery_placeholder = st.empty()

# å½“æœ‰èŠå¤©æ¶ˆæ¯æ—¶ï¼Œæ¸…ç©ºå ä½ç¬¦
if len(st.session_state.messages) > 0:
    gallery_placeholder.empty()

# Display or clear chat messages
total_image_num = 0
for message in st.session_state.messages:
    with st.chat_message(message['role']):
        st.markdown(message['content'])
        show_one_or_multiple_images(message, total_image_num, is_input=message['role'] == 'user')
        if 'image' in message and message['role'] == 'user':
            total_image_num += len(message['image'])

input_disable_flag = (len(model_list) == 0) or total_image_num + len(uploaded_files) > max_image_limit
if lan == 'English':
    st.sidebar.button('Clear Chat History',
                      on_click=partial(combined_func, func_list=[clear_chat_history, clear_file_uploader]))
    if input_disable_flag:
        prompt = st.chat_input('Too many images have been uploaded. Please clear the history.',
                               disabled=input_disable_flag)
    else:
        prompt = st.chat_input('Send messages to Pac-Dent MediaMind', disabled=input_disable_flag)
else:
    st.sidebar.button('æ¸…ç©ºèŠå¤©è®°å½•', on_click=partial(combined_func, func_list=[clear_chat_history, clear_file_uploader]))
    if input_disable_flag:
        prompt = st.chat_input('è¾“å…¥çš„å›¾ç‰‡å¤ªå¤šäº†ï¼Œè¯·æ¸…ç©ºå†å²è®°å½•ã€‚', disabled=input_disable_flag)
    else:
        prompt = st.chat_input('ç»™ "Pac-Dent MediaMind" å‘é€æ¶ˆæ¯', disabled=input_disable_flag)

alias_instructions = {
    'ç›®æ ‡æ£€æµ‹': 'åœ¨ä»¥ä¸‹å›¾åƒä¸­è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œå¹¶æ ‡å‡ºæ‰€æœ‰ç‰©ä½“ã€‚',
    'æ£€æµ‹': 'åœ¨ä»¥ä¸‹å›¾åƒä¸­è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œå¹¶æ ‡å‡ºæ‰€æœ‰ç‰©ä½“ã€‚',
    'object detection': 'Please identify and label all objects in the following image.',
    'detection': 'Please identify and label all objects in the following image.'
}

if prompt:
    prompt = alias_instructions[prompt] if prompt in alias_instructions else prompt
    image_list = uploaded_pil_images
    
    # å°†è§†é¢‘å¸§æ·»åŠ åˆ°å‘é€ç»™AIçš„å›¾åƒåˆ—è¡¨ä¸­ï¼Œä½†ä¸æ˜¾ç¤ºåœ¨èŠå¤©è®°å½•ä¸­
    all_images_for_ai = image_list.copy()
    if 'video_frames' in st.session_state and st.session_state.video_frames:
        all_images_for_ai.extend(st.session_state.video_frames)
    
    # å¦‚æœæœ‰å­—å¹•ï¼Œå°†å­—å¹•ä¿¡æ¯æ·»åŠ åˆ°æç¤ºä¸­
    enhanced_prompt = prompt
    if 'video_subtitles' in st.session_state and st.session_state.video_subtitles:
        subtitle_text = ""
        for subtitle in st.session_state.video_subtitles:
            # ç®€å•æå–å­—å¹•æ–‡æœ¬ï¼ˆå»é™¤æ—¶é—´æˆ³ï¼‰
            lines = subtitle['content'].split('\n')
            text_lines = [line for line in lines if line and not line.startswith('WEBVTT') and not '-->' in line and not line.isdigit()]
            subtitle_text += " ".join(text_lines) + "\n"
        
        if subtitle_text.strip():
            enhanced_prompt = f"{prompt}\n\nVideo subtitles for context:\n{subtitle_text.strip()}"
    
    # èŠå¤©è®°å½•ä¸­åªä¿å­˜ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡
    st.session_state.messages.append(
        {'role': 'user', 'content': prompt, 'image': image_list, 'filenames': save_filenames})
    
    with st.chat_message('user'):
        st.write(prompt)
        show_one_or_multiple_images(st.session_state.messages[-1], total_image_num, is_input=True)
    if image_list:
        clear_file_uploader()

# Generate a new response if last message is not from assistant
if len(st.session_state.messages) > 0 and st.session_state.messages[-1]['role'] != 'assistant':
    with st.chat_message('assistant'):
        with st.spinner('Thinking...'):
            if not prompt:
                prompt = st.session_state.messages[-1]['content']
            
            # ä¸´æ—¶ä¿®æ”¹æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼šä»…åœ¨æ²¡æœ‰ä¸Šä¼ å›¾ç‰‡æ—¶ï¼Œæ‰é™„åŠ å°‘é‡è§†é¢‘å¸§ä¸æˆªæ–­å­—å¹•
            messages_for_ai = st.session_state.messages.copy()
            if 'video_frames' in st.session_state and st.session_state.video_frames:
                last_user_message = messages_for_ai[-1]
                has_user_images = 'image' in last_user_message and last_user_message['image'] and len(last_user_message['image']) > 0
                if not has_user_images:
                    # æ— ä¸Šä¼ å›¾ç‰‡æ—¶é™„åŠ å…¨éƒ¨è§†é¢‘å¸§ï¼ˆåç»­åœ¨ generate_response ä¸­é€å¸§ä¸²è¡Œå¤„ç†ï¼‰
                    limited_frames = st.session_state.video_frames
                    last_user_message = last_user_message.copy()
                    last_user_message['image'] = limited_frames
                    
                    # å¦‚æœæœ‰å­—å¹•ï¼Œæ·»åŠ æˆªæ–­åçš„çº¯æ–‡æœ¬ï¼ˆæœ€å¤š2000å­—ç¬¦ï¼‰
                    if 'video_subtitles' in st.session_state and st.session_state.video_subtitles:
                        subtitle_text = ""
                        for subtitle in st.session_state.video_subtitles:
                            lines = subtitle['content'].split('\n')
                            text_lines = [line for line in lines if line and not line.startswith('WEBVTT') and not '-->' in line and not line.isdigit()]
                            subtitle_text += " ".join(text_lines) + "\n"
                        subtitle_text = subtitle_text.strip()
                        if len(subtitle_text) > 2000:
                            subtitle_text = subtitle_text[:2000] + '...'
                        if subtitle_text:
                            last_user_message['content'] = f"{last_user_message['content']}\n\nVideo subtitles for context:\n{subtitle_text}"
                    messages_for_ai[-1] = last_user_message
            
            response = generate_response(messages_for_ai)
            message = {'role': 'assistant', 'content': response}
        with st.spinner('Drawing...'):
            if '<ref>' in response:
                has_returned_image = find_bounding_boxes(response)
                message['image'] = [has_returned_image] if has_returned_image else []
            if '```drawing-instruction' in response:
                has_returned_image = query_image_generation(response, sd_worker_url=sd_worker_url)
                message['image'] = [has_returned_image] if has_returned_image else []
            st.session_state.messages.append(message)
            show_one_or_multiple_images(message, total_image_num, is_input=False)

if len(st.session_state.messages) > 0:
    col1, col2, col3, col4 = st.columns([1, 1, 1, 1.3])
    text1 = 'Clear Chat History' if lan == 'English' else 'æ¸…ç©ºèŠå¤©è®°å½•'
    text2 = 'Regenerate' if lan == 'English' else 'é‡æ–°ç”Ÿæˆ'
    text3 = 'Copy' if lan == 'English' else 'å¤åˆ¶å›ç­”'
    with col1:
        st.button(text1, on_click=partial(combined_func, func_list=[clear_chat_history, clear_file_uploader]),
                  key='clear_chat_history_button')
    with col2:
        st.button(text2, on_click=regenerate, key='regenerate_button')

print(st.session_state.messages)
save_chat_history()
